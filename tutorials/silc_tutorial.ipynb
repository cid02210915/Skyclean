{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7eb5ce0",
   "metadata": {},
   "source": [
    "# SILC Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e2ef0",
   "metadata": {},
   "source": [
    "## SILC Pipeline Overview\n",
    "\n",
    "The **Scale-discretised, directional Internal Linear Combination (SILC)** pipeline performs component separation in CMB analysis. \n",
    "\n",
    "###  Pipeline\n",
    "\n",
    "| Step | Process | Description |\n",
    "|------|---------|-------------|\n",
    "| **1️** | **Data Acquisition** | Download CMB, noise, and foreground maps, currently using Planck simulations  → `download.py` |\n",
    "| **2️** | **Map Processing** | Handle instrumental beams, reduce resolution, and convert from HEALPix → McEwen-Wiaux (MW) sampling  → `map_tools.py` `map_processing.py`|\n",
    "| **3️** | **Wavelet Analysis** | Apply multi-scale wavelet transforms with customisable filter scales and directional components  → `map_processing.py` |\n",
    "| **4** | **SPIN Algorithm** | Compute Scale-discretised, directional Internal Linear Combination on each wavelet scale  → `ilc.py` |\n",
    "| **5️** | **Map Synthesis** | Combine all scales into a single, clean ILC component map  → `ilc.py` |\n",
    "\n",
    "- `visualise.py` module provides capability to compute and plot maps and power spectra. \n",
    "- `file_templates.py` module contains the directory structure for storing and loading data throughout the pipeline.\n",
    "\n",
    "###  Current Capabilities\n",
    "\n",
    "> **Primary Target**: CMB extraction \n",
    "\n",
    "> **Future goals**: Generalisation to extract any astrophysical component (e.g., thermal Sunyaev-Zel'dovich effect, synchrotron emission)\n",
    "\n",
    "This notebook will decompose the pipeline to show the main processes occurring at each stage, for one realisation of the ILC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014996a2",
   "metadata": {},
   "source": [
    "## Import \n",
    "\n",
    "**Note:** To run modules in the terminal, use e.g. `python3 -m skyclean.silc.map_processing` while in the Skyclean home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import jax\n",
    "\n",
    "# Add the parent directory to Python path for proper module resolution\n",
    "# Get current working directory and navigate to parent (assumes notebook is in examples/ folder)\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "print(f\"Added to Python path: {parent_dir}\")\n",
    "\n",
    "# Check JAX devices\n",
    "print(f\"\\nJAX Configuration:\")\n",
    "print(f\"JAX devices available: {jax.devices()}\")\n",
    "print(f\"JAX default backend: {jax.default_backend()}\")\n",
    "\n",
    "# Import SILC modules\n",
    "from skyclean.silc.download import DownloadData\n",
    "from skyclean.silc.file_templates import FileTemplates\n",
    "from skyclean.silc.map_tools import MWTools, HPTools, SamplingConverters\n",
    "from skyclean.silc.map_processing import ProcessMaps\n",
    "from skyclean.silc.ilc import SILCTools, ProduceSILC\n",
    "from skyclean.silc.pipeline import Pipeline\n",
    "from skyclean.silc.utils import *\n",
    "from skyclean.silc.visualise import Visualise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e5af0",
   "metadata": {},
   "source": [
    "## Download \n",
    "\n",
    "Skyclean currently downloads maps from the [Planck simulation archive](https://pla.esac.esa.int/#home). The downloaded maps include noise and foregrounds. The noise maps have a total of 300 random realisations. \n",
    "\n",
    "A problem was encountered with the Planck CMB simulations where the instrumental beams produced different maps in different frequency channels when deconvolved. This breaks the ILC assumption that the CMB is frequency channel-independent. Thus, a new approach was decided on where `cmb_spectrum.txt` is used to generate random CMB realisations. Make sure this is in your data directory before running downloads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4867ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INITIALISE PARAMS\n",
    "\n",
    "# Initialise file templates\n",
    "data_directory = \"data/\"   # Local data storage\n",
    "files = FileTemplates(data_directory)\n",
    "file_templates = files.file_templates\n",
    "\n",
    "# Define components to download\n",
    "components = [\"cmb\", \"sync\", \"dust\", \"noise\"]\n",
    "\n",
    "# Define frequencies (Planck channels in GHz)\n",
    "# frequencies = [\"030\", \"044\", \"070\", \"100\", \"143\", \"217\", \"353\", \"545\", \"857\"]  # this is the full set\n",
    "frequencies = [\"030\", \"044\", \"070\"] # let's work with a subset. \n",
    "\n",
    "# Download configuration\n",
    "realisations = 1           # Download just one realisation for this example\n",
    "start_realisation = 0      # Start from realisation 0\n",
    "\n",
    "print(f\"Target: {realisations} realisation(s) starting from #{start_realisation}\")\n",
    "print(f\"Storage: {data_directory}\")\n",
    "\n",
    "# Set processing parameters\n",
    "realisation = 0\n",
    "desired_lmax = 64  # Lets choose a lower lmax for faster processing\n",
    "standard_fwhm_rad = np.radians(5/60)  # 5 arcminute beam\n",
    "\n",
    "# Set wavelet parameters\n",
    "lam = 4.0  # Lambda parameter controlling wavelet scaling\n",
    "N_directions = 1  # Number of directional components (1 = axisymmetric)\n",
    "L = desired_lmax + 1  # L parameter for s2wav (lmax + 1)\n",
    "wavelet_components = [\"cfn\"] # only take wavelet transform of CFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c09975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the downloader\n",
    "downloader = DownloadData(\n",
    "    components=components,\n",
    "    frequencies=frequencies, \n",
    "    realisations=realisations,\n",
    "    start_realisation=start_realisation,\n",
    "    directory=data_directory\n",
    ")\n",
    "\n",
    "# Download everything at once\n",
    "downloader.download_all()  \n",
    "\n",
    "print(\"Download complete. Ready for map processing.\")\n",
    "print(\"Check your data/CMB_realisations directory for the files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f385d767",
   "metadata": {},
   "source": [
    "##  Process Maps\n",
    "\n",
    "Map processing handles instrumental beams, reduces resolution, and converts between HEALPix and McEwen-Wiaux sampling schemes. This step creates the total maps (CFN: CMB + Foreground + Noise) that will be used for wavelet analysis.\n",
    "\n",
    "We will start by showing the map processing and wavelet transform tools available in `skyclean`, and then show how the pipeline can run these processes automatically.\n",
    "\n",
    "**Note:** Experimentally, the CFN would be observed directly, but the Skyclean pipeline starts by building these maps from individual components. This modularity is necessary for model training where the known CMB is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031384f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map Processing Example\n",
    "# This demonstrates the key map processing steps\n",
    "\n",
    "print(\"Map Processing Parameters:\")\n",
    "print(f\"  Components: {components}\")\n",
    "print(f\"  Frequencies: {frequencies}\")\n",
    "print(f\"  Target lmax: {desired_lmax}\")\n",
    "print(f\"  Standard beam FWHM: {np.degrees(standard_fwhm_rad)*60:.1f} arcmin\")\n",
    "\n",
    "\n",
    "# Calculate target nside from lmax\n",
    "nside = HPTools.get_nside_from_lmax(desired_lmax)\n",
    "print(f\"  Target nside: {nside}\")\n",
    "\n",
    "print(\"PROCESSING INDIVIDUAL COMPONENTS\")\n",
    "\n",
    "# Store processed maps for visualisation\n",
    "processed_maps = {}\n",
    "original_maps = {}\n",
    "\n",
    "for freq in frequencies:\n",
    "    processed_maps[freq] = {}\n",
    "    original_maps[freq] = {}\n",
    "    \n",
    "    print(f\"\\nProcessing frequency: {freq} GHz\")\n",
    "    \n",
    "    for comp in components:\n",
    "        print(f\"  Processing {comp}...\")\n",
    "        filepath = file_templates[comp].format(frequency=freq, realisation=realisation)\n",
    "    \n",
    "        original_map = hp.read_map(filepath, verbose=False) # load in the .fits file\n",
    "        original_maps[freq][comp] = original_map\n",
    "        \n",
    "        # Apply unit conversion if needed\n",
    "        converted_map = HPTools.unit_convert(original_map.copy(), freq)\n",
    "        \n",
    "        # Process the map\n",
    "        if comp == \"noise\":\n",
    "            # Noise: only reduce resolution (no beam convolution)\n",
    "            processed_map, _ = HPTools.reduce_hp_map_resolution(converted_map, lmax=desired_lmax, nside=nside)\n",
    "        else:\n",
    "            # CMB and foregrounds: beam convolution + resolution reduction\n",
    "            processed_map = HPTools.convolve_and_reduce(converted_map, lmax=desired_lmax, nside=nside, standard_fwhm_rad=standard_fwhm_rad)\n",
    "        \n",
    "        processed_maps[freq][comp] = processed_map\n",
    "    \n",
    "\n",
    "\n",
    "print(\"CREATING TOTAL MAPS (CFN)\")\n",
    "# Create CFN (CMB + Foreground + Noise) maps; this functionality exists in map_processing.py but we will show it explicitly here.\n",
    "cfn_maps = {}\n",
    "\n",
    "for freq in frequencies:\n",
    "    print(f\"\\nCreating CFN map for {freq} GHz...\")\n",
    "    \n",
    "    # Initialise empty map\n",
    "    cfn_map = np.zeros(hp.nside2npix(nside), dtype=np.float64)\n",
    "    \n",
    "    # Sum all components\n",
    "    for comp in components:\n",
    "        cfn_map += processed_maps[freq][comp]\n",
    "        print(f\"  + Added {comp}\")\n",
    "    \n",
    "    cfn_maps[freq] = cfn_map\n",
    "    print(f\"  Total RMS: {np.std(cfn_map):.2e}\")\n",
    "    \n",
    "    # Save CFN map to the standard location (following map_processing.py pattern)\n",
    "    cfn_filepath = file_templates[\"cfn\"].format(frequency=freq, realisation=realisation, lmax=desired_lmax)\n",
    "    hp.write_map(cfn_filepath, cfn_map, overwrite=True)\n",
    "    print(f\"  Saved CFN map to: {cfn_filepath}\")\n",
    "\n",
    "print(\"\\nCONVERTING CFN MAPS TO MW SAMPLING\")\n",
    "# Convert HP CFN maps to MW sampling (used for wavelet transforms)\n",
    "cfn_mw_maps = {}\n",
    "\n",
    "for freq in frequencies:\n",
    "    print(f\"Converting CFN map to MW sampling for {freq} GHz...\")\n",
    "    \n",
    "    # Convert HEALPix CFN map to MW sampling\n",
    "    cfn_mw_map = SamplingConverters.hp_map_2_mw_map(cfn_maps[freq], lmax=desired_lmax)\n",
    "    cfn_mw_maps[freq] = cfn_mw_map\n",
    "    \n",
    "    # Convert back to HP for verification\n",
    "    cfn_hp_reconstructed = SamplingConverters.mw_map_2_hp_map(cfn_mw_map, lmax=desired_lmax)\n",
    "    \n",
    "    # Report conversion statistics\n",
    "    original_rms = np.std(cfn_maps[freq])\n",
    "    reconstructed_rms = np.std(cfn_hp_reconstructed)\n",
    "    conversion_error = np.std(cfn_maps[freq] - cfn_hp_reconstructed)\n",
    "    \n",
    "    print(f\"  MW map shape: {cfn_mw_map.shape}\")\n",
    "    print(f\"  RMS before conversion: {original_rms:.2e}\")\n",
    "    print(f\"  RMS after HP→MW→HP: {reconstructed_rms:.2e}\")\n",
    "    print(f\"  Conversion error RMS: {conversion_error:.2e}\")\n",
    "\n",
    "\n",
    "print(\"VISUALISATION\")\n",
    "\n",
    "\n",
    "# Plot original maps (before processing)\n",
    "print(\"\\nPlotting original maps...\")\n",
    "n_comp = len(components)\n",
    "n_freq = len(frequencies)\n",
    "\n",
    "fig = plt.figure(figsize=(5*n_freq, 4*n_comp))\n",
    "for i, comp in enumerate(components):\n",
    "    for j, freq in enumerate(frequencies):\n",
    "        panel = i*n_freq + j + 1\n",
    "        hp.mollview(\n",
    "            original_maps[freq][comp],\n",
    "            fig=fig.number,\n",
    "            sub=(n_comp, n_freq, panel),\n",
    "            title=f\"Original {comp} @ {freq} GHz\",\n",
    "            unit=\"K\",\n",
    "            cbar=True\n",
    "        )\n",
    "plt.suptitle(\"Original Maps (Before Processing)\", fontsize=16, y=0.95)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot processed maps (after beam convolution and resolution reduction)\n",
    "print(\"\\nPlotting processed maps...\")\n",
    "fig = plt.figure(figsize=(5*n_freq, 4*n_comp))\n",
    "for i, comp in enumerate(components):\n",
    "    for j, freq in enumerate(frequencies):\n",
    "        panel = i*n_freq + j + 1\n",
    "        hp.mollview(\n",
    "            processed_maps[freq][comp],\n",
    "            fig=fig.number,\n",
    "            sub=(n_comp, n_freq, panel),\n",
    "            title=f\"Processed {comp} @ {freq} GHz\",\n",
    "            unit=\"K\",\n",
    "            cbar=True\n",
    "        )\n",
    "plt.suptitle(\"Processed Maps (After Beam Convolution & Resolution Reduction)\", fontsize=16, y=0.95)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot CFN maps\n",
    "print(\"\\nPlotting CFN maps...\")\n",
    "fig = plt.figure(figsize=(5*n_freq, 4))\n",
    "for j, freq in enumerate(frequencies):\n",
    "    panel = j + 1\n",
    "    hp.mollview(\n",
    "        cfn_maps[freq],\n",
    "        fig=fig.number,\n",
    "        sub=(1, n_freq, panel),\n",
    "        title=f\"CFN @ {freq} GHz\",\n",
    "        unit=\"K\",\n",
    "        cbar=True\n",
    "    )\n",
    "plt.suptitle(\"Total Maps (CMB + Foregrounds + Noise)\", fontsize=16, y=0.9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualise MW CFN maps using MWTools.visualise_mw_map\n",
    "print(\"\\nVisualising MW CFN maps using MWTools...\")\n",
    "for freq in frequencies:\n",
    "    print(f\"\\nPlotting CFN @ {freq} GHz in MW sampling...\")\n",
    "    MWTools.visualise_mw_map(\n",
    "        cfn_mw_maps[freq], \n",
    "        title=f\"CFN MW Sampling @ {freq} GHz\",\n",
    "        directional=False  # Using directional=False for regular MW maps\n",
    "    )\n",
    "\n",
    "# Plot difference maps\n",
    "print(\"\\nPlotting conversion difference maps...\")\n",
    "fig = plt.figure(figsize=(5*n_freq, 4))\n",
    "for j, freq in enumerate(frequencies):\n",
    "    panel = j + 1\n",
    "    cfn_hp_from_mw = SamplingConverters.mw_map_2_hp_map(cfn_mw_maps[freq], lmax=desired_lmax)\n",
    "    difference_map = cfn_maps[freq] - cfn_hp_from_mw\n",
    "    hp.mollview(\n",
    "        difference_map,\n",
    "        fig=fig.number,\n",
    "        sub=(1, n_freq, panel),\n",
    "        title=f\"HP - MW→HP Difference @ {freq} GHz\",\n",
    "        unit=\"K\",\n",
    "        cbar=True\n",
    "    )\n",
    "plt.suptitle(\"Conversion Error Maps (Original HP - MW→HP)\", fontsize=16, y=0.9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original resolution: nside={hp.get_nside(original_maps[frequencies[0]][components[0]])}\")\n",
    "print(f\"Processed resolution: nside={nside}\")\n",
    "print(f\"Standard beam applied: {np.degrees(standard_fwhm_rad)*60:.1f} arcmin FWHM\")\n",
    "print(f\"MW map dimensions: {cfn_mw_maps[frequencies[0]].shape}\")\n",
    "\n",
    "# Clear large variables\n",
    "del original_maps, processed_maps, cfn_maps, cfn_mw_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d681ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet Transform Demonstration\n",
    "# Apply multi-scale wavelet transforms to the 030 GHz CFN map\n",
    "\n",
    "# Load the saved CFN map for 030 GHz\n",
    "target_freq = \"030\"\n",
    "print(f\"Loading CFN map for {target_freq} GHz...\")\n",
    "\n",
    "cfn_filepath = file_templates[\"cfn\"].format(frequency=target_freq, realisation=realisation, lmax=desired_lmax)\n",
    "cfn_map = hp.read_map(cfn_filepath, verbose=False)\n",
    "\n",
    "# Convert to MW sampling for wavelet transforms\n",
    "cfn_mw_map = SamplingConverters.hp_map_2_mw_map(cfn_map, lmax=desired_lmax)\n",
    "print(f\"Converted CFN @ {target_freq} GHz to MW sampling, shape: {cfn_mw_map.shape}\")\n",
    "\n",
    "# WAVELET FILTER VISUALISATION\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"AXISYMMETRIC WAVELET FILTER VISUALISATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Visualise the axisymmetric wavelet filters\n",
    "print(\"Displaying axisymmetric wavelet filters used in the decomposition...\")\n",
    "MWTools.visualise_axisym_wavelets(L=L, lam=lam)\n",
    "\n",
    "# Apply wavelet transform\n",
    "print(f\"\\nApplying wavelet transform to CFN @ {target_freq} GHz...\")\n",
    "wavelet_coeffs, _ = MWTools.wavelet_transform_from_map(\n",
    "    cfn_mw_map, \n",
    "    L=L, \n",
    "    N_directions=N_directions, \n",
    "    lam=lam\n",
    ")\n",
    "\n",
    "# Report decomposition structure\n",
    "n_scales = len(wavelet_coeffs)  # Total number of scales (scaling coeffs = scale 0, then wavelet scales 1, 2, ...)\n",
    "print(f\"Total number of scales: {n_scales}\")\n",
    "print(f\"Components: scale 0 (scaling) + scales 1-{n_scales-1} (wavelets)\")\n",
    "\n",
    "for i, coeff in enumerate(wavelet_coeffs):\n",
    "    scale_lmax = coeff.shape[1] - 1  # MW map shape is (L, 2*L-1), so lmax = L-1\n",
    "    if i == 0:\n",
    "        print(f\"Scale 0 (scaling) coefficients shape: {coeff.shape}, effective lmax: {scale_lmax}\")\n",
    "    else:\n",
    "        print(f\"Scale {i} (wavelet) coefficients shape: {coeff.shape}, effective lmax: {scale_lmax}\")\n",
    "\n",
    "# Visualise original CFN map in MW sampling\n",
    "print(f\"\\nOriginal CFN map @ {target_freq} GHz:\")\n",
    "MWTools.visualise_mw_map(\n",
    "    cfn_mw_map, \n",
    "    title=f\"Original CFN {target_freq} GHz\",\n",
    "    directional=False\n",
    ")\n",
    "\n",
    "# Visualise all wavelet components (scaling coefficients + wavelet scales)\n",
    "print(f\"\\nWavelet decomposition components:\")\n",
    "for scale in range(len(wavelet_coeffs)):\n",
    "    scale_lmax = wavelet_coeffs[scale].shape[1] - 1\n",
    "    if scale == 0:\n",
    "        continue # for some reason scale 0 wont plot\n",
    "    else:\n",
    "        print(f\"Scale {scale} - Wavelet coefficients (lmax={scale_lmax}):\")\n",
    "        title = f\"Scale {scale} Wavelet Coefficients {target_freq} GHz (lmax={scale_lmax})\"\n",
    "    \n",
    "    MWTools.visualise_mw_map(\n",
    "        wavelet_coeffs[scale][0],  # First (and only) direction for axisymmetric case\n",
    "        title=title,\n",
    "        directional=False\n",
    "    )\n",
    "\n",
    "# Test synthesis (reconstruction) from wavelet coefficients\n",
    "print(f\"\\nTesting wavelet synthesis (reconstruction)...\")\n",
    "reconstructed_mw = MWTools.inverse_wavelet_transform(\n",
    "    wavelet_coeffs, \n",
    "    L=L, \n",
    "    N_directions=N_directions, \n",
    "    lam=lam\n",
    ")\n",
    "\n",
    "# Visualise reconstructed map\n",
    "print(f\"\\nReconstructed CFN map:\")\n",
    "MWTools.visualise_mw_map(\n",
    "    reconstructed_mw, \n",
    "    title=f\"Reconstructed CFN {target_freq} GHz\",\n",
    "    directional=False\n",
    ")\n",
    "\n",
    "# Compute and visualise reconstruction error\n",
    "reconstruction_error_mw = cfn_mw_map - reconstructed_mw\n",
    "print(f\"\\nReconstruction error map:\")\n",
    "MWTools.visualise_mw_map(\n",
    "    reconstruction_error_mw, \n",
    "    title=f\"Reconstruction Error {target_freq} GHz\",\n",
    "    directional=False\n",
    ")\n",
    "\n",
    "max_error = np.max(np.abs(reconstruction_error_mw))\n",
    "print(f\"Maximum absolute error: {max_error:.2e}\")\n",
    "print(f\"\\nWavelet transform demonstration complete for {target_freq} GHz\")\n",
    "print(f\"Successfully decomposed map into {n_scales} total scales:\")\n",
    "print(f\"  - Scale 0: Scaling coefficients (large-scale structure)\")\n",
    "print(f\"  - Scales 1-{n_scales-1}: Wavelet coefficients (progressively finer scales)\")\n",
    "print(f\"Each scale captures different angular scales of the CMB and foreground\")\n",
    "\n",
    "# Clear large variables\n",
    "del cfn_map, cfn_mw_map, wavelet_coeffs, reconstructed_mw, reconstruction_error_mw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ProcessMaps(\n",
    "    components,\n",
    "    wavelet_components,\n",
    "    frequencies,\n",
    "    1,\n",
    "    start_realisation=0,\n",
    "    desired_lmax=desired_lmax,\n",
    "    directory=data_directory,\n",
    ")\n",
    "processor.produce_and_save_cfns()\n",
    "\n",
    "processor.produce_and_save_wavelet_transforms(\n",
    "        N_directions,\n",
    "        lam,\n",
    "    )\n",
    "\n",
    "# Clear processor to free memory\n",
    "print(\"Clearing processor to free memory...\")\n",
    "del processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa139dd",
   "metadata": {},
   "source": [
    "## SILC Stage\n",
    " \n",
    "Once decomposing the CFN into wavelet scales, our goal is to perform internal linear combination (ILC) on each scale. An optimisation formula is applied to compute the weighting for each frequency channel that minimises the variance of the foreground and noise. This is subject to the constraint that $\\sum_i w_i(p) a_i = 1$ where $i$ are the frequencies, $p$ the pixel, $w_i$ and the weights and $a_i$ is the power spectral density of the component we want to preserve (currently, the CMB, for which $a_i = 1 \\forall \\, i$). \n",
    "\n",
    "First, we run the SILC stage of the pipeline on the GPU using the `ProduceSILC` class. The results should be saved to your data directory such that this only needs to be performed once. Then, we will confirm at an example scale that $\\sum_i w_i(p) = 1$ as demanded by the ILC procedure. Next, we will show the ILC synthesised map across the scales. Finally, we will find the spectra of the CMB, CFN and ILC synthesised map. If the procedure is succesful, we expect the ILC power spectrum to be closer to the CMB than the ILC as a function of multipole. However, since the ILC only works up to second order moments. This will build the case for applying an ML enhancement stage, which will be covered in the next notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb26cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SILC Algorithm - Run the Scale-discretised Internal Linear Combination\n",
    "print(\"Setting up SILC parameters...\")\n",
    "\n",
    "# Check what device JAX is using for SILC\n",
    "print(f\"JAX devices available: {jax.devices()}\")\n",
    "print(f\"JAX default backend: {jax.default_backend()}\")\n",
    "\n",
    "# Initialise SILC producer\n",
    "ilc_producer = ProduceSILC(\n",
    "    ilc_components=[\"cfn\"],  # Process CFN maps to extract CMB\n",
    "    frequencies=frequencies,\n",
    "    realisations=1,\n",
    "    start_realisation=0,\n",
    "    lmax=desired_lmax,\n",
    "    N_directions=N_directions,\n",
    "    lam=lam,\n",
    "    synthesise=True,\n",
    "    directory=data_directory,\n",
    ")\n",
    "\n",
    "\n",
    "# Run the SILC pipeline\n",
    "print(\"\\nRunning SILC pipeline...\")\n",
    "print(\"This will:\")\n",
    "print(\"  1. Load wavelet coefficients for each frequency and scale\")\n",
    "print(\"  2. Double resolution of wavelet maps\")\n",
    "print(\"  3. Calculate covariance matrices at each scale\")\n",
    "print(\"  4. Compute ILC weight vectors\")\n",
    "print(\"  5. Create ILC maps at each scale\")\n",
    "print(\"  6. Trim back to original resolution\")\n",
    "print(\"  7. Synthesize final ILC map from all scales\")\n",
    "\n",
    "ilc_producer.process_wavelet_maps(\n",
    "    save_intermediates=True,  # Save intermediate results for analysis\n",
    "    visualise=False  # We'll do visualisation separately\n",
    ")\n",
    "\n",
    "# Note: Keep ilc_producer for the next cell's analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88030a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive SILC Results Visualisation\n",
    "print(\"SILC Results Analysis and Visualisation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get the middle scale for weight map for an example scale to plot\n",
    "middle_scale_idx = len(ilc_producer.scales)// 2\n",
    "middle_scale = list(ilc_producer.scales)[middle_scale_idx]\n",
    "print(f\"Analysing scale {middle_scale} (middle scale out of {len(ilc_producer.scales)} total scales)\")\n",
    "\n",
    "# 1. WEIGHT MAP ANALYSIS\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"1. ILC WEIGHT MAP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load and visualise weight maps for the middle scale\n",
    "weight_vector_path = file_templates['weight_vector_matrices'].format(\n",
    "    scale=middle_scale, \n",
    "    realisation=realisation, \n",
    "    lmax=desired_lmax, \n",
    "    lam=lam\n",
    ")\n",
    "\n",
    "if os.path.exists(weight_vector_path):\n",
    "    weight_vector = np.load(weight_vector_path)\n",
    "    print(f\"Weight vector shape: {weight_vector.shape}\")\n",
    "    print(f\"Weight vector represents contributions from {len(frequencies)} frequencies\")\n",
    "    \n",
    "    # Visualise weight maps for each frequency\n",
    "    for freq_idx, freq in enumerate(frequencies):\n",
    "        print(f\"\\nWeight map for {freq} GHz:\")\n",
    "        MWTools.visualise_mw_map(\n",
    "            weight_vector[:, :, freq_idx],\n",
    "            title=f\"ILC Weight Map - {freq} GHz - Scale {middle_scale}\",\n",
    "            directional=False\n",
    "        )\n",
    "        \n",
    "    # 2. VERIFY WEIGHT SUM = 1 (ILC constraint)\n",
    "    print(f\"\\n\" + \"-\" * 40)\n",
    "    print(\"2. ILC CONSTRAINT VERIFICATION: $\\sum_i w_i = 1$\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Sum weights across all frequencies\n",
    "    weight_sum = np.sum(weight_vector, axis=2)\n",
    "    \n",
    "    # Calculate weight statistics\n",
    "    print(f\"\\nWeight Statistics:\")\n",
    "    print(f\"  Mean weight sum: {np.mean(weight_sum):.6f}\")\n",
    "    print(f\"  Std weight sum: {np.std(weight_sum):.6f}\")\n",
    "    print(f\"  Target (ideal): 1\")\n",
    "    \n",
    "    # Individual frequency weight statistics\n",
    "    print(f\"\\nIndividual Frequency Weight Statistics:\")\n",
    "    for freq_idx, freq in enumerate(frequencies):\n",
    "        freq_weights = weight_vector[:, :, freq_idx]\n",
    "        print(f\"  {freq} GHz - Mean: {np.mean(freq_weights):.6f}, Std: {np.std(freq_weights):.6f}\")\n",
    "    \n",
    "    # Check constraint satisfaction\n",
    "    weight_error = np.abs(weight_sum - 1.0)\n",
    "    max_error = np.max(weight_error)\n",
    "    mean_error = np.mean(weight_error)\n",
    "    \n",
    "    print(f\"\\nILC Constraint Error Analysis:\")\n",
    "    print(f\"  Mean absolute error: {mean_error:.2e}\")\n",
    "    print(f\"  Max absolute error: {max_error:.2e}\")\n",
    "    \n",
    "    # Visualise weight sum map to check ILC constraint\n",
    "    print(f\"\\nVisualising weight sum map (should be ~ 1 everywhere):\")\n",
    "    MWTools.visualise_mw_map(\n",
    "        weight_sum,\n",
    "        title=f\"Weight Sum Map - Scale {middle_scale} (ILC Constraint Check)\",\n",
    "        directional=False\n",
    "    )\n",
    "        \n",
    "else:\n",
    "    print(f\"Weight vector file not found: {weight_vector_path}\")\n",
    "\n",
    "# 3. ILC SYNTHESISED MAP\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"3. ILC SYNTHESISED MAP VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load and visualise the final ILC synthesised map\n",
    "ilc_synth_path = file_templates['ilc_synth'].format(\n",
    "    realisation=realisation, \n",
    "    lmax=desired_lmax, \n",
    "    lam=lam\n",
    ")\n",
    "\n",
    "if os.path.exists(ilc_synth_path):\n",
    "    ilc_synth_map = np.load(ilc_synth_path)\n",
    "    print(f\"ILC synthesised map shape: {ilc_synth_map.shape}\")\n",
    "    \n",
    "    # Convert to HEALPix for visualisation\n",
    "    if len(ilc_synth_map.shape) == 2:  # MW sampling\n",
    "        ilc_hp_map = SamplingConverters.mw_map_2_hp_map(ilc_synth_map, lmax=desired_lmax)\n",
    "    else:  # Already HEALPix\n",
    "        ilc_hp_map = ilc_synth_map\n",
    "    \n",
    "    \n",
    "    # Visualise ILC map\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    hp.mollview(\n",
    "        ilc_hp_map,\n",
    "        title=\"SILC Extracted CMB Map\",\n",
    "        unit=\"K\",\n",
    "        cbar=True\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(f\"ILC synthesised map not found: {ilc_synth_path}\")\n",
    "\n",
    "# 4. POWER SPECTRA COMPARISON\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"4. POWER SPECTRA ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialise visualiser for power spectra\n",
    "visualiser = Visualise(\n",
    "    frequencies=frequencies,\n",
    "    realisation=realisation,\n",
    "    lmax=desired_lmax,\n",
    "    lam_list=[lam],\n",
    "    directory=data_directory\n",
    ")\n",
    "\n",
    "# Components to compare: CMB, CFN, and ILC\n",
    "components_to_plot = ['cmb', 'cfn', 'ilc_synth']\n",
    "print(f\"Plotting power spectra for: {components_to_plot}\")\n",
    "\n",
    "# Visualise power spectra\n",
    "visualiser.visualise_power_spectra(\n",
    "    comps=components_to_plot,\n",
    ")\n",
    "\n",
    "\n",
    "# Clear large variables to prevent memory overload\n",
    "if 'weight_vector' in locals():\n",
    "    del weight_vector\n",
    "if 'weight_sum' in locals():\n",
    "    del weight_sum\n",
    "if 'ilc_synth_map' in locals():\n",
    "    del ilc_synth_map\n",
    "if 'ilc_hp_map' in locals():\n",
    "    del ilc_hp_map\n",
    "del ilc_producer, visualiser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
